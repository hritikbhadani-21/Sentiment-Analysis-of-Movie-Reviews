{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5332b139-af3c-485c-97ea-4bfb9c1780ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hriti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hriti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re  # for regex\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "# Download NLTK resources if not already downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe52f9d9-29d3-4fe5-8364-8f07d8550286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n",
      "sentiment\n",
      "positive    25000\n",
      "negative    25000\n",
      "Name: count, dtype: int64\n",
      "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('IMDB-Dataset.csv')\n",
    "print(data.shape)\n",
    "print(data.head())\n",
    "data.info()\n",
    "print(data.sentiment.value_counts())\n",
    "print(data.review[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37159fea-41ce-4a9a-8e61-1f68277ab354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  one review mention watch 1 oz episod hook righ...  positive\n",
      "1  wonder littl product film techniqu unassum old...  positive\n",
      "2  thought wonder way spend time hot summer weeke...  positive\n",
      "3  basic famili littl boy jake think zombi closet...  negative\n",
      "4  petter mattei love time money visual stun film...  positive\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning functions\n",
    "def clean(text):\n",
    "    cleaned = re.compile(r'<.*?>')\n",
    "    return re.sub(cleaned, '', text)\n",
    "\n",
    "data.review = data.review.apply(clean)\n",
    "\n",
    "def is_special(text):\n",
    "    rem = ''\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            rem += i\n",
    "        else:\n",
    "            rem += ' '\n",
    "    return rem\n",
    "\n",
    "data.review = data.review.apply(is_special)\n",
    "\n",
    "def to_lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "data.review = data.review.apply(to_lower)\n",
    "\n",
    "def rem_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    return [w for w in words if w not in stop_words]\n",
    "\n",
    "data.review = data.review.apply(rem_stopwords)\n",
    "\n",
    "def stem_txt(text):\n",
    "    ss = SnowballStemmer('english')\n",
    "    return \" \".join([ss.stem(w) for w in text])\n",
    "\n",
    "data.review = data.review.apply(stem_txt)\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01f6e4cd-33ef-40fa-b2e6-09ca023c8e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (50000, 1000)\n",
      "y.shape = (50000,)\n",
      "Train shapes: X = (40000, 1000), y = (40000,)\n",
      "Test shapes: X = (10000, 1000), y = (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for model training\n",
    "X = np.array(data.review)\n",
    "y = np.array(data.sentiment)\n",
    "cv = CountVectorizer(max_features=1000)\n",
    "X = cv.fit_transform(X).toarray()\n",
    "print(\"X.shape =\", X.shape)\n",
    "print(\"y.shape =\", y.shape)\n",
    "\n",
    "# Split the data\n",
    "trainx, testx, trainy, testy = train_test_split(X, y, test_size=0.2, random_state=9)\n",
    "print(\"Train shapes: X = {}, y = {}\".format(trainx.shape, trainy.shape))\n",
    "print(\"Test shapes: X = {}, y = {}\".format(testx.shape, testy.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af702256-8acf-4c71-877c-c9abcd4b5591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial =  0.831\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "mnb = MultinomialNB(alpha=1.0, fit_prior=True)\n",
    "mnb.fit(trainx, trainy)\n",
    "\n",
    "# Predictions\n",
    "ypm = mnb.predict(testx)\n",
    "print(\"Multinomial = \", accuracy_score(testy, ypm))\n",
    "\n",
    "# Save the model\n",
    "pickle.dump(mnb, open('model1.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd5df458-7b27-4672-a3f6-b73149ecf69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment:  ['negative']\n"
     ]
    }
   ],
   "source": [
    "# Prepare for single review prediction\n",
    "rev = \"\"\"Terrible. Complete trash. Brainless tripe. Insulting to anyone who isn't an 8 year old fan boy. \n",
    "Im actually pretty disgusted that this movie is making the money it is - what does it say about the people who \n",
    "brainlessly hand over the hard earned cash to be 'entertained' in this fashion and then come here to leave a \n",
    "positive 8.8 review?? Oh yes, they are morons. Its the only sensible conclusion to draw. How anyone can rate \n",
    "this movie amongst the pantheon of great titles is beyond me.\"\"\"\n",
    "\n",
    "f1 = clean(rev)\n",
    "f2 = is_special(f1)\n",
    "f3 = to_lower(f2)\n",
    "f4 = rem_stopwords(f3)\n",
    "f5 = stem_txt(f4)\n",
    "\n",
    "# Creating the input vector\n",
    "input_vector = cv.transform([f5]).toarray()\n",
    "y_pred = mnb.predict(input_vector)\n",
    "\n",
    "print(\"Predicted Sentiment: \", y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586d5e76-8115-4bd6-8bb6-9d1b582088f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
